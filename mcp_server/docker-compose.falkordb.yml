# Docker Compose for Graphiti MCP Server with FalkorDB
# Optimized for production deployment with <500MB target
#
# Usage:
#   1. Copy .env.falkordb.example to .env and configure your settings
#   2. Run: docker-compose -f docker-compose.falkordb.yml up -d
#   3. Access MCP server at http://localhost:8000
#
# For development, add --build flag to rebuild containers

services:
  falkordb:
    image: falkordb/falkordb:edge
    container_name: graphiti-falkordb
    ports:
      - "${FALKORDB_PORT:-6379}:6379" # Redis-compatible protocol port
      - "${FALKORDB_UI_PORT:-3000}:3000" # FalkorDB Browser UI
    volumes:
      - ./data:/data
    environment:
      # FalkorDB performance optimizations
      - FALKOR_QUERY_TIMEOUT=${FALKOR_QUERY_TIMEOUT:-300000} # 5 minutes
      - FALKOR_MAX_MEMORY=${FALKOR_MAX_MEMORY:-512MB}
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "6379", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "1.0"
        reservations:
          memory: 256M
          cpus: "0.5"
    networks:
      - graphiti_network

  graphiti-mcp:
    image: sacahan/graphiti-mcp:latest
    container_name: graphiti-mcp
    depends_on:
      falkordb:
        condition: service_healthy
    environment:
      # Database configuration - defaults optimized for container deployment
      - GRAPHITI_DB_TYPE=falkordb
      - FALKORDB_CONNECTION_STRING=${FALKORDB_CONNECTION_STRING:-redis://falkordb:6379}
      - GRAPHITI_DB_NAME=${GRAPHITI_DB_NAME:-graphiti_db}

      # LLM configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY:?OPENAI_API_KEY is required}
      - MODEL_NAME=${MODEL_NAME:-gpt-4.1-mini}
      - SMALL_MODEL_NAME=${SMALL_MODEL_NAME:-gpt-4.1-nano}
      - EMBEDDER_MODEL_NAME=${EMBEDDER_MODEL_NAME:-text-embedding-3-small}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.0}

      # Performance tuning for FalkorDB
      - SEMAPHORE_LIMIT=${SEMAPHORE_LIMIT:-20}

      # Container environment
      - MCP_SERVER_HOST=0.0.0.0
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports:
      - "127.0.0.1:8050:8000" # MCP server HTTP/SSE endpoint
    command: ["python", "graphiti_mcp_server.py", "--transport", "sse"]
    healthcheck:
      test:
        ["CMD-SHELL", "timeout 5 bash -c '</dev/tcp/localhost/8000' || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "1.0"
        reservations:
          memory: 256M
          cpus: "0.5"
    networks:
      - graphiti_network

networks:
  graphiti_network:
    driver: bridge
